---
layout: page
title: Multi-modal
description: >
  Here you should be able to find everything you need to know to accomplish the most common tasks when blogging with Hydejack.
hide_description: True
sitemap: false
permalink: /multimodal/
use_math: true
---

Cufft 님 여기 설명 좀 해주세요.

## ViT
* [ViT]{:.heading.flip-title} --- An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
{:.related-posts.faded}

## Visual Language Models
* [Flamingo]{:.heading.flip-title} --- Flamingo: a Visual Language Model for Few-Shot Learning
* [ImageBind]{:.heading.flip-title} --- ImageBind: One Embedding Space To Bind Them All
* [Lens]{:.heading.flip-title} --- Towards Language Models That Can See: Computer Vision Through the LENS of Natural Language
{:.related-posts.faded}

## Representation Learning
* [data2vec]{:.heading.flip-title} --- data2vec, A General Framework for Self-supervised Learning in Speech Vision and Language
{:.related-posts.faded}


[data2vec]: https://agency301.github.io/multi-modal/2023-07-29-data2vec,-A-General-Framework-for-Self-supervised-Learning-in-Speech-Vision-and-Language/
[Flamingo]: https://agency301.github.io/multi-modal/2023-07-28-Flamingo/  
[ImageBind]: https://agency301.github.io/multi-modal/2023-07-28-ImageBind/
[Lens]: https://agency301.github.io/multi-modal/2023-07-28-Lens/
[ViT]: https://agency301.github.io/multi-modal/2023-07-28-ViT/